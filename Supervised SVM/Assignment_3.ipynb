{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7088f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e99592c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66155.925095</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34415.153966</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>57317.170063</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42709.534201</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66952.688845</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clientid        income        age         loan  default\n",
       "0         1  66155.925095  59.017015  8106.532131        0\n",
       "1         2  34415.153966  48.117153  6564.745018        0\n",
       "2         3  57317.170063  63.108049  8020.953296        0\n",
       "3         4  42709.534201  45.751972  6103.642260        0\n",
       "4         5  66952.688845  18.584336  8770.099235        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"original.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74738ac9",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "Checked if is there any nan value in the dataset and dropped the index for 3 Nan value which is in the age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef138e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clientid    0\n",
      "income      0\n",
      "age         3\n",
      "loan        0\n",
      "default     0\n",
      "dtype: int64\n",
      "\n",
      "Total records before removing NAN values: 2000\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "print(f\"\\nTotal records before removing NAN values: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f29e15c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total records after removing NAN values: 1997\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(f\"\\nTotal records after removing NAN values: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b285a1a9",
   "metadata": {},
   "source": [
    "<b>Unbalanced Data set</b><br>\n",
    "Here we have 1714 negative samples while only 283 positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eccc1234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1714\n",
       "1     283\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4e5def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "minority = df[df.default == 1]\n",
    "majority = df[df.default == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cb734",
   "metadata": {},
   "source": [
    "Upsampled the data to match the majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aae297e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1714\n",
       "0    1714\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_upsampled = resample(minority, replace=True, n_samples=1714, random_state=7)\n",
    "df_upsampled = pd.concat([minority_upsampled, majority])\n",
    "df_upsampled.default.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e668714",
   "metadata": {},
   "source": [
    "### Data Scaling\n",
    "Here, we have used the MinMaxScaler function with feature range 0 to 1. It scales the values to a specific value range[0,1] without changing the shape of the original distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbb645e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.values\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_upsampled_noscale = df_upsampled\n",
    "scaler.fit(df_upsampled)\n",
    "df_upsampled_scaled = pd.DataFrame(scaler.transform(df_upsampled))\n",
    "df_upsampled_scaled.columns = features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a555a",
   "metadata": {},
   "source": [
    "Extracting Features from our pre-processed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "466a4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_upsampled_scaled.drop(['clientid', 'default'], axis=1)\n",
    "y = df_upsampled_scaled['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd6fb0",
   "metadata": {},
   "source": [
    "Spliting the data with 80% train size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48d55e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0908d0",
   "metadata": {},
   "source": [
    "### Support Vector Classifier\n",
    "<li><b>kernel</b> parameters selects the type of hyperplane used to separate the data. Using ‘linear’ will use a linear hyperplane, ‘rbf’ and ‘poly’ uses a non linear hyper-plane.</li>\n",
    "<li><b>gamma</b> is a parameter for non linear hyperplanes. The higher the gamma value it tries to exactly fit the training data set.</li>\n",
    "<li><b>C</b> is the penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying the training points correctly.</li>\n",
    "Below Cell represents the 'rbf' kernel with oprimized gamma and C value in order to achieve a acurate result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbcee213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533527696793003"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_classifier = svm.SVC(kernel='rbf', gamma=0.8, C=10).fit(X_train, y_train)\n",
    "y_pred = svc_classifier.predict(X_test)\n",
    "svc_score = svc_classifier.score(X_test, y_test)\n",
    "svc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ebd191",
   "metadata": {},
   "source": [
    "Here we have achieved the 92% precision with the accuracy of 95%, which describes that our model is a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0d759f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy: 0.95 \n",
      " recall: 0.99 \n",
      " precision: 0.92 \n",
      " f1_score: 0.95\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "print(f' accuracy: {accuracy:.2f} \\n recall: {recall:.2f} \\n precision: {precision:.2f} \\n f1_score: {f1score:.2f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4efcd6d",
   "metadata": {},
   "source": [
    "By using 'cross_val_score' we can cross validate our training samples with k-fold, we have used cv=10 means it will randomize the sample in 10 different groups. by taking the average of that 10 values we can get average cross validation accuracy score estimation.<br>\n",
    "Here we achieved the 96.20% average accuracy with polynomial kernel and C=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f944db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9620735512250015\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(kernel='poly', C=10)\n",
    "scores = cross_val_score(svc, X, y, cv=10)\n",
    "# print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ad205",
   "metadata": {},
   "source": [
    "Here we achieved the 96.79% average accuracy with rbf kernel, gamma=1.2 and C=100, which almost similar to the score achieved by 'poly' kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59dd945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97084548 0.96793003 0.96793003 0.98250729 0.95626822 0.97667638\n",
      " 0.97376093 0.96501458 0.9502924  0.96783626]\n",
      "0.9679061599577174\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(kernel='rbf', gamma=1.2, C=10)\n",
    "scores = cross_val_score(svc, X, y, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99bb14",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "Here I have tried to perform cross validation without performing the data scaling.<br>\n",
    "We can observe here that with the same gamma and C value it gives us 99.85% average accuracy, which actually not good because our model performs overfitting here because of the values in all 3 columns are not on the similar scale.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5557300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         0.99708455 1.         1.\n",
      " 1.         0.99125364 0.99707602 1.        ]\n",
      "average svc score without scaling the data: 99.85\n"
     ]
    }
   ],
   "source": [
    "X1 = df_upsampled_noscale.drop(['clientid', 'default'], axis=1)\n",
    "y1 = df_upsampled_noscale['default']\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=7)\n",
    "svc = svm.SVC(kernel='rbf', gamma=1.2, C=10)\n",
    "scores_noscale = cross_val_score(svc, X1, y1, cv=10)\n",
    "print(scores_noscale)\n",
    "print(f\"average svc score without scaling the data: {scores_noscale.mean()*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f99de",
   "metadata": {},
   "source": [
    " Observing the average accuracy with the different C values for 'poly' kernel. By increasing the C value we are getting better accuracy but computational time increased drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65267301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C value 0.1: 95.24%\n",
      "For C value 1: 95.86%\n",
      "For C value 10: 96.21%\n",
      "For C value 50: 96.53%\n"
     ]
    }
   ],
   "source": [
    "C_values = [0.1, 1, 10, 50]\n",
    "for C in C_values:\n",
    "    svc = svm.SVC(kernel='poly', C=C)\n",
    "    scores = cross_val_score(svc, X, y, cv=10)\n",
    "    print(f\"For C value {C}: {scores.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57e21e",
   "metadata": {},
   "source": [
    "For 'rbf', By increasing the C value we are getting much better result and the computation time is comparatively low as compare to the 'poly'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0f9b9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C value 0.1: 95.80%\n",
      "For C value 1: 96.91%\n",
      "For C value 10: 98.19%\n",
      "For C value 100: 98.92%\n"
     ]
    }
   ],
   "source": [
    "C_values = [0.1, 1, 10, 100]\n",
    "for C in C_values:\n",
    "    svc = svm.SVC(kernel='rbf', C=C)\n",
    "    scores = cross_val_score(svc, X, y, cv=10)\n",
    "    print(f\"For C value {C}: {scores.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117e118",
   "metadata": {},
   "source": [
    "With different gamma values we are getting the better accaurary for higher value of gamma, which is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54d4c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For gamma value 0.1: 93.23%\n",
      "For gamma value 1: 95.59%\n",
      "For gamma value 10: 97.29%\n",
      "For gamma value 100: 98.77%\n"
     ]
    }
   ],
   "source": [
    "gamma_values = [0.1, 1, 10, 100]\n",
    "for gamma in gamma_values:\n",
    "    svc = svm.SVC(kernel='rbf', gamma=gamma)\n",
    "    scores = cross_val_score(svc, X, y, cv=10)\n",
    "    print(f\"For gamma value {gamma}: {scores.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8795a21c",
   "metadata": {},
   "source": [
    "Note:- I have noticed that with 'poly' kernel and higher C value it takes very long in computation as compare to 'rbf'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
